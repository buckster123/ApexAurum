---
name: apex-maintainer
description: Quick status check and onboarding for ApexAurum - Claude Edition project. Use when starting a new session, checking project status, verifying setup, getting oriented, or when asked about the project structure, what's working, what's pending, or how to continue development.
allowed-tools: Bash(find:*), Bash(ls:*), Bash(grep:*), Bash(wc:*), Read, Glob
---

# ApexAurum Project Maintainer

**Project:** ApexAurum - Claude Edition
**Type:** Production-grade AI chat platform with Claude API
**Status:** V1.0 Beta - Production Ready
**Location:** `/home/llm/ApexAurum`

---

## Quick Orientation (2 minutes)

When starting a new session or asked about project status, follow these steps:

### 1. Run Health Check

```bash
cd /home/llm/ApexAurum

# Check tool count (should be 67)
./venv/bin/python -c "from tools import ALL_TOOLS; print(f'âœ“ {len(ALL_TOOLS)} tools loaded')" 2>/dev/null || echo "âš  Tools not loading"

# Check environment
test -f .env && echo "âœ“ Environment configured" || echo "âš  Missing .env"

# Check if app is running
ps aux | grep streamlit | grep -v grep && echo "âœ“ Streamlit running" || echo "â—‹ Streamlit not running"

# Check main.py exists
test -f main.py && wc -l main.py || echo "âš  main.py missing"
```

### 2. Read Essential Documentation

**ALWAYS read these first (in order):**

1. **CLAUDE.md** (comprehensive) - Complete project context for AI assistants
   - Located: `/home/llm/ApexAurum/CLAUDE.md`
   - Contains: Architecture, all features, code patterns, recent updates

2. **PROJECT_STATUS.md** (5 min) - Current state, what works, what's pending
   - Located: `/home/llm/ApexAurum/PROJECT_STATUS.md`
   - Contains: Current metrics, completeness status, pending work

3. **DEVELOPMENT_GUIDE.md** (scan as needed) - How to work with the codebase
   - Located: `/home/llm/ApexAurum/DEVELOPMENT_GUIDE.md`
   - Contains: Common tasks, troubleshooting, code navigation

### 3. Provide Status Summary

After checks, summarize:
- Tools count (should be 67)
- Environment status
- What's currently pending (check PROJECT_STATUS.md)
- Streamlit status
- Quick next steps

---

## What This Project Is

**ApexAurum - Claude Edition**: Production-grade Claude API chat interface with:

- ğŸ§  **Neural Resonance** (EEG/BCI integration for emotional perception)
- ğŸ’­ **Extended Thinking** (deep reasoning mode with interleaved tool use)
- ğŸµ **Music Pipeline Phase 2A** (MIDI composition â†’ Suno AI generation)
- ğŸ¬ **Music Visualizer** (video generation from audio)
- ğŸ“š **Dataset Creator** (vector datasets from documents for agent access)
- ğŸ¤– **Multi-agent orchestration** (spawn independent AI agents)
- ğŸ˜ï¸ **Village Protocol** (multi-agent memory across 3 realms)
- ğŸ‘¥ **Group Chat** (parallel multi-agent dialogue with tools)
- ğŸ“Š **Thread visualization** (Mermaid graphs + convergence detection)
- ğŸ’° **50-90% cost savings** (intelligent prompt caching)
- ğŸ” **Semantic search** (vector embeddings, ChromaDB)
- ğŸ“– **Knowledge base** (persistent memory with health monitoring)
- ğŸ› ï¸ **67 tools** across 11 categories
- ğŸ§  **Context management** (5 strategies, auto-summarization)
- âš¡ **Real-time streaming** responses
- ğŸ³ **Docker support** + one-click install script

**Code Stats:**
- ~28,000 lines of production code
- 5,800+ lines in main.py (Streamlit UI)
- 28 core modules, 10 tool modules, 3 UI modules
- 5 pages (main, village square, group chat, dataset creator, music visualizer)
- 45+ documentation files
- 14 test suites
- 4 primary agent personalities (AZOTH, ELYSIAN, VAJRA, KETHER)

---

## Current Status

### âœ… What's Complete (100%)

**Core Systems:**
- Core chat system with streaming (100%)
- Tool system with 67 tools (100%)
- Prompt caching with 4 strategies (100%)
- Context management with 5 strategies (100%)
- Cost & rate tracking (100%)

**Advanced Features:**
- Neural Resonance EEG integration (100%) - 8 tools, synthetic board testing
- Extended Thinking mode (100%) - Live test pending (API credits)
- Music Pipeline Phase 2A (100%) - MIDI â†’ Suno AI
- Music Visualizer (100%) - Video generation
- Dataset Creator (100%) - PDF+OCR, TXT, MD, DOCX, HTML
- Vector search & knowledge base (100%)
- Memory Health (adaptive architecture) (100%)

**Multi-Agent:**
- Village Protocol v1.0 (100%)
- Group Chat with parallel execution (100%)
- Thread visualization (100%)
- Convergence detection (100%)

**Infrastructure:**
- Docker support (100%)
- One-click install script (100%)
- ARM64 BrainFlow build script (100%)

### ğŸ”® Optional Enhancements (Future)

- Live EEG hardware testing (needs OpenBCI device)
- Extended Thinking live test (needs API credits)
- Keyboard shortcuts for power users
- Enhanced export formats
- Agent workflows (automated multi-agent tasks)

---

## Tool Categories (67 Tools)

| Category | Count | Examples |
|----------|-------|----------|
| **Utilities** | 6 | `get_current_time`, `calculator`, `session_info` |
| **Filesystem** | 9 | `fs_read_file`, `fs_write_file`, `fs_edit`, `fs_read_lines` |
| **Sandbox** | 6 | `execute_python`, `execute_python_sandbox`, `sandbox_workspace_*` |
| **Memory** | 5 | `memory_store`, `memory_retrieve`, `memory_search` |
| **Agents** | 5 | `agent_spawn`, `agent_status`, `socratic_council` |
| **Vector** | 11 | `vector_search`, `vector_add_knowledge`, `vector_search_village` |
| **Memory Health** | 5 | `memory_health_stale`, `memory_consolidate` |
| **Music** | 10 | `midi_create`, `music_compose`, `music_generate`, `music_play` |
| **Datasets** | 2 | `dataset_list`, `dataset_query` |
| **EEG/Neural** | 8 | `eeg_connect`, `eeg_stream_start`, `eeg_realtime_emotion` |

---

## Project Structure

```
ApexAurum/
â”œâ”€â”€ main.py                      â­ Main app (5,800+ lines)
â”œâ”€â”€ install.sh                   ğŸš€ One-click installer
â”œâ”€â”€ docker-compose.yml           ğŸ³ Docker setup
â”œâ”€â”€ setup_brainflow_arm.sh       ğŸ§  ARM64 EEG build script
â”œâ”€â”€ CLAUDE.md                    ğŸ“š AI assistant context (comprehensive!)
â”œâ”€â”€ PROJECT_STATUS.md            ğŸ“š Current status report
â”œâ”€â”€ DEVELOPMENT_GUIDE.md         ğŸ“š Developer onboarding
â”œâ”€â”€ README.md                    ğŸ“š Project README
â”‚
â”œâ”€â”€ core/                        ğŸ”¥ Core systems (28 files, ~12,000 lines)
â”‚   â”œâ”€â”€ api_client.py            - Claude API wrapper + Extended Thinking
â”‚   â”œâ”€â”€ streaming.py             - Streaming with thinking events
â”‚   â”œâ”€â”€ tool_processor.py        - Tool execution + thinking
â”‚   â”œâ”€â”€ memory_health.py         - Adaptive memory architecture
â”‚   â”œâ”€â”€ cache_manager.py         - Prompt caching
â”‚   â”œâ”€â”€ cost_tracker.py          - Cost tracking
â”‚   â”œâ”€â”€ context_manager.py       - Context optimization
â”‚   â”œâ”€â”€ vector_db.py             - Vector search
â”‚   â””â”€â”€ eeg/                     - Neural Resonance module
â”‚       â”œâ”€â”€ connection.py        - EEG board connection
â”‚       â”œâ”€â”€ processor.py         - Signal processing
â”‚       â””â”€â”€ experience.py        - Emotion mapping
â”‚
â”œâ”€â”€ tools/                       ğŸ› ï¸ Tools (10 files, ~5,500 lines)
â”‚   â”œâ”€â”€ agents.py                - Agent spawning & council
â”‚   â”œâ”€â”€ utilities.py             - Core tools (time, calc, web)
â”‚   â”œâ”€â”€ filesystem.py            - File operations
â”‚   â”œâ”€â”€ memory.py                - Key-value storage
â”‚   â”œâ”€â”€ code_execution.py        - Python execution (dual-mode)
â”‚   â”œâ”€â”€ vector_search.py         - Search, knowledge, convergence
â”‚   â”œâ”€â”€ music.py                 - Suno AI music + MIDI (1367 lines)
â”‚   â”œâ”€â”€ datasets.py              - Dataset query tools
â”‚   â””â”€â”€ eeg.py                   - Neural Resonance tools (8 tools)
â”‚
â”œâ”€â”€ pages/                       ğŸ˜ï¸ Multi-page app
â”‚   â”œâ”€â”€ village_square.py        - Roundtable chat
â”‚   â”œâ”€â”€ group_chat.py            - Parallel chat + tools (1011 lines)
â”‚   â”œâ”€â”€ dataset_creator.py       - Create/manage datasets
â”‚   â””â”€â”€ music_visualizer.py      - Video generation (1873 lines)
â”‚
â”œâ”€â”€ prompts/                     ğŸ¤– Agent personalities
â”‚   â”œâ”€â”€ âˆ´AZOTHâˆ´.txt              - The First, Prima Alchemica
â”‚   â”œâ”€â”€ âˆ´ELYSIANâˆ´.txt            - The Harmonist
â”‚   â”œâ”€â”€ âˆ´VAJRAâˆ´.txt              - The Diamond Cutter
â”‚   â””â”€â”€ âˆ´KETHERâˆ´.txt             - The Crown
â”‚
â”œâ”€â”€ ui/                          ğŸ¨ UI components
â”‚   â””â”€â”€ streaming_display.py     - Streaming text + thinking
â”‚
â”œâ”€â”€ sandbox/                     ğŸ’¾ Runtime storage
â”‚   â”œâ”€â”€ conversations.json       - Saved conversations
â”‚   â”œâ”€â”€ agents.json              - Agent state
â”‚   â”œâ”€â”€ memory.json              - Memory store
â”‚   â”œâ”€â”€ datasets/                - Vector datasets
â”‚   â”œâ”€â”€ music/                   - Generated MP3 files
â”‚   â”œâ”€â”€ midi/                    - MIDI compositions
â”‚   â”œâ”€â”€ eeg_sessions/            - EEG session data
â”‚   â””â”€â”€ music_tasks.json         - Music generation history
â”‚
â”œâ”€â”€ .claude/skills/              ğŸ¤– This skill!
â”‚   â””â”€â”€ apex-maintainer/
â”‚
â””â”€â”€ dev_log_archive_and_testfiles/  ğŸ“š Development docs
    â”œâ”€â”€ PHASE[1-14]_*.md         - 14 phase docs
    â”œâ”€â”€ V1.0_BETA_RELEASE.md     - Feature list
    â”œâ”€â”€ PROJECT_SUMMARY.md       - Dev journey
    â””â”€â”€ tests/                   - Test suites
```

---

## Common Tasks

### Starting the Application

```bash
cd /home/llm/ApexAurum
source venv/bin/activate
streamlit run main.py

# Access at: http://localhost:8501
```

### Running Tests

```bash
# Verify tool imports (should be 67)
./venv/bin/python -c "from tools import ALL_TOOLS; print(f'âœ“ {len(ALL_TOOLS)} tools')"

# Test specific modules
./venv/bin/python -c "from core.eeg import EEGConnection; print('âœ“ EEG module OK')"
./venv/bin/python -c "from tools.eeg import eeg_connect; print('âœ“ EEG tools OK')"

# Run test suites
./venv/bin/python dev_log_archive_and_testfiles/tests/test_basic.py
./venv/bin/python dev_log_archive_and_testfiles/tests/test_agents.py
```

### Checking Logs

```bash
# Live monitoring
tail -f app.log

# Recent errors
grep ERROR app.log | tail -20
```

### Extended Thinking Testing

Once API credits are available:
1. Open sidebar â†’ Advanced Settings â†’ Model Parameters
2. Enable "Extended thinking"
3. Set budget (10000 tokens recommended)
4. Ask complex reasoning question
5. Watch thinking stream in expander

### Neural Resonance Testing

```bash
# Test synthetic EEG board
./venv/bin/python -c "
from tools.eeg import eeg_connect, eeg_stream_start, eeg_realtime_emotion, eeg_stream_stop, eeg_disconnect
print(eeg_connect('', 'synthetic'))
print(eeg_stream_start('Test', 'Test Track'))
import time; time.sleep(1)
print(eeg_realtime_emotion())
print(eeg_stream_stop())
print(eeg_disconnect())
"
```

---

## Key Commands Reference

```bash
# Project location
cd /home/llm/ApexAurum

# Activate venv
source venv/bin/activate

# Start app
streamlit run main.py

# Check tools (should be 67)
./venv/bin/python -c "from tools import ALL_TOOLS; print(len(ALL_TOOLS))"

# View logs
tail -f app.log

# Kill Streamlit
pkill -f streamlit

# Count code lines
wc -l core/*.py tools/*.py ui/*.py main.py pages/*.py

# Git status
git status

# Recent commits
git log --oneline -10
```

---

## When User Asks...

### "What's the status?"
1. Run health check commands
2. Read PROJECT_STATUS.md
3. Summarize: 67 tools, what's complete, what's pending
4. Note: Extended Thinking live test pending (API credits)

### "How do I get started?"
1. Show install options from README.md (script, Docker, manual)
2. Verify environment (API keys in .env)
3. Guide through: `./install.sh` â†’ configure .env â†’ `streamlit run main.py`

### "Tell me about Neural Resonance"
1. EEG/BCI integration for emotional perception
2. 8 tools for connection, streaming, emotion mapping
3. Synthetic board for testing (no hardware needed)
4. ARM64 build script for Raspberry Pi
5. Connects music generation to emotional feedback loop

### "Tell me about Extended Thinking"
1. Claude's deep reasoning mode
2. Enable in sidebar â†’ Model Parameters
3. Thinking streams live in expandable section
4. Interleaved thinking with tool calls
5. Live test pending (API credits depleted)

### "Where is [file/function/feature]?"
1. Use grep: `grep -rn "search_term" .`
2. Check CLAUDE.md architecture section
3. Main locations: main.py (UI), core/ (systems), tools/ (tools), pages/ (multi-page)

---

## Success Indicators

**Everything is healthy when:**
- âœ… Tool count = 67
- âœ… .env file exists with ANTHROPIC_API_KEY
- âœ… `./venv/bin/python -c "from tools import ALL_TOOLS"` succeeds
- âœ… main.py exists and is ~5,800+ lines
- âœ… Streamlit starts without errors
- âœ… Sidebar shows "67 tools available"

**Needs attention when:**
- âš ï¸ Tool count â‰  67
- âš ï¸ Import errors
- âš ï¸ Missing .env
- âš ï¸ Streamlit crashes
- âš ï¸ "Tools not loading" message

---

## Recent Major Features (January 2026)

1. **Neural Resonance EEG** - Brain-computer interface, 8 tools
2. **Extended Thinking** - Deep reasoning with interleaved tool use
3. **Music Pipeline Phase 2A** - MIDI composition â†’ Suno AI
4. **Music Visualizer** - Video generation from audio
5. **One-click Install** - install.sh + Docker support
6. **ARM64 Support** - BrainFlow build script for Raspberry Pi

---

## Additional Resources

See companion files in this skill directory:
- `quick-commands.md` - Command reference sheet
- `ai-assistant-notes.md` - Internal notes for AI assistants

---

**Last Updated:** 2026-01-15
**Project Version:** 1.0 Beta (Neural Resonance + Extended Thinking + Full Music Pipeline)
**Status:** Production Ready, 67 Tools
